# 残差块：在旁边加一个通路，多支持一个简单的小模型
# 残差块加在哪里，都比较随意

# Resnet架构：类似vgg和googleNet，替换成了ResNet块

# ResNet 101 50 34 512(刷分) 18 152

# 重要作用：可以把网络变得更深

# 一条通路正常计算，另一条1*1卷积或者直接连接，最后将二者相加（两条通路上的结果）

# 核心思想:f(x) = x + g(x)，g(x)是之前的逻辑，如果发现x已经可以有很好的效果了，那么g(x)就会拿不到梯度

# 如果训练时候加入了大量的augmentation，那么最后的测试精度是有可能比训练精度要高的

# Resnet如何处理梯度消失，训练超过1000层的网络
# residual将乘法的链式求导法则变为加法
# y'' = f(x) + g(f(x)) ，