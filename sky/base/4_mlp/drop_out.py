# 正则：避免权重太大，导致过拟合

# 丢弃法：在层之间加噪音
# 扰动： 以概率p变为0,概率1-p变为 xi/(1-p)，其期望值是不变的
# 用法：在全连接的输出上进行drop_out，尝作用于mlp的隐藏层输出上
# drop out属于正则，只在训练的时候使用正则，所以用于部署的模型没有见过Dropout层
# dropout的p也属于超参数

# todo： 正则的含义是什么、正则项

# dropout -> fc，BN -> conv
